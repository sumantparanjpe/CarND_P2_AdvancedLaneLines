{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Video Processing Pipeline   \n",
    "\n",
    "* Image undistort\n",
    "* Color transform & level thresholding\n",
    "* Gradient detector for edges\n",
    "* Perspective transform to dewarp camera image\n",
    "* Lane detect using historical tracking data\n",
    "* Calculate curvature metrics\n",
    "* Warp back to original image geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages imported ...\n",
      "Loaded camera calibration data from file ...\n",
      "Loaded camera warp data from file ...\n",
      "[MoviePy] >>>> Building video ./Resources/test_videos_output/project_video.mp4\n",
      "[MoviePy] Writing video ./Resources/test_videos_output/project_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|███████████████████████████████████████████████████████████████████████████████▎| 125/126 [00:55<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./Resources/test_videos_output/project_video.mp4 \n",
      "\n",
      "Wall time: 57.3 s\n"
     ]
    }
   ],
   "source": [
    "#Importing packages required for notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Markdown\n",
    "import cv2\n",
    "import pickle\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline\n",
    "print(\"Packages imported ...\")\n",
    "\n",
    "# Load Camera Calibration Data\n",
    "cameraData = pickle.load( open('./Resources/pickled_data/camera_calibration.p', 'rb' ) )\n",
    "mtx, dist = map(cameraData.get, ('mtx', 'dist'))\n",
    "print(\"Loaded camera calibration data from file ...\")\n",
    "\n",
    "# Load camera warp data\n",
    "transMatrix = pickle.load( open('./Resources/pickled_data/perspective_transform.p', 'rb' ) )\n",
    "M, Minv = map(transMatrix.get, ('M', 'Minv'))\n",
    "print(\"Loaded camera warp data from file ...\")\n",
    "\n",
    "# Define conversions in x and y from pixels space to meters\n",
    "ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "# global array to hold lane indicators across video frames\n",
    "prev_left_lane_inds = []\n",
    "prev_right_lane_inds = []\n",
    "\n",
    "# Undistort image frame usign camera distorition matrix\n",
    "def image_undistort (image):\n",
    "    return cv2.undistort(image, mtx, dist, None, mtx) \n",
    "    \n",
    "# Transform color space to HSL+RGB --> RHS component space\n",
    "def color_transform (image):\n",
    "    hls_img =cv2.cvtColor(image, cv2.COLOR_BGR2HLS)\n",
    "    rgb_img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    #return np.dstack((rgb_img[:,:,0], hls_img[:,:,0], hls_img[:,:,2]))\n",
    "    #return np.dstack(( hls_img[:,:,2], hls_img[:,:,2], hls_img[:,:,2]))\n",
    "    return hls_img\n",
    "\n",
    "# Select white+yellow colors from RGB & HSL spaces, threshold to a binary image\n",
    "def color_select (image):\n",
    "    # Color space transforms\n",
    "    img_hls = cv2.cvtColor(image, cv2.COLOR_BGR2HLS)\n",
    "    img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    img_lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    \n",
    "    # RGB, HLS & Lab color thresholds for yellow & white \n",
    "    # combined yellow & white thresholds\n",
    "    lowrgb_white = np.array([100,100,200], dtype = \"uint8\")\n",
    "    highrgb_white = np.array([255,255,255], dtype = \"uint8\")\n",
    "    lowrgb_yellow = np.array([255,180,0], dtype = \"uint8\")\n",
    "    highrgb_yellow = np.array([255,255,170], dtype = \"uint8\")\n",
    "    lowhls_yellow = np.array([20,120,130], dtype = \"uint8\")\n",
    "    highhls_yellow = np.array([45,200,255], dtype = \"uint8\")\n",
    "    lowlab_yellow = np.array([0,0,154], dtype = \"uint8\")\n",
    "    highlab_yellow = np.array([0,0,255], dtype = \"uint8\")\n",
    "    \n",
    "    # RGB white\n",
    "    mask = cv2.inRange(img_rgb, lowrgb_white, highrgb_white)\n",
    "    rgb_ww = cv2.bitwise_and(img_rgb, img_rgb, mask = mask).astype(np.uint8)\n",
    "    rgb_ww = cv2.cvtColor(rgb_ww, cv2.COLOR_RGB2GRAY)\n",
    "    rgb_w = np.zeros_like(rgb_ww)\n",
    "    rgb_w[(rgb_ww >= 80) & (rgb_ww <= 255)] = 1\n",
    "    \n",
    "    # RGB yellow\n",
    "    mask = cv2.inRange(img_rgb, lowrgb_yellow, highrgb_yellow)\n",
    "    rgb_yy = cv2.bitwise_and(img_rgb, img_rgb, mask = mask).astype(np.uint8)\n",
    "    rgb_yy = cv2.cvtColor(rgb_yy, cv2.COLOR_RGB2GRAY)\n",
    "    rgb_y = np.zeros_like(rgb_yy)\n",
    "    rgb_y[(rgb_yy >= 20) & (rgb_yy <= 255)] = 1\n",
    "\n",
    "    # HLS yellow\n",
    "    mask = cv2.inRange(img_hls, lowhls_yellow, highhls_yellow)\n",
    "    hls_yy = cv2.bitwise_and(img_hls, img_hls, mask = mask).astype(np.uint8)\n",
    "    hls_yy = cv2.cvtColor(hls_yy, cv2.COLOR_HLS2RGB)\n",
    "    hls_yy = cv2.cvtColor(hls_yy, cv2.COLOR_RGB2GRAY)\n",
    "    hls_y = np.zeros_like(hls_yy)\n",
    "    hls_y[(hls_yy >= 50) & (hls_yy <= 255)] = 1\n",
    "\n",
    "    # Lab yellow\n",
    "    mask = cv2.inRange(img_lab, lowlab_yellow, highlab_yellow)\n",
    "    lab_yy = cv2.bitwise_and(img_lab, img_lab, mask = mask).astype(np.uint8)\n",
    "    lab_yy = cv2.cvtColor(lab_yy, cv2.COLOR_HLS2RGB)\n",
    "    lab_yy = cv2.cvtColor(lab_yy, cv2.COLOR_RGB2GRAY)\n",
    "    lab_y = np.zeros_like(lab_yy)\n",
    "    lab_y[(lab_yy >= 50) & (lab_yy <= 255)] = 1\n",
    "\n",
    "    # combined yellow+white thresholds\n",
    "    bin_whiteyellow = np.zeros_like(hls_y)\n",
    "    bin_whiteyellow[(hls_y == 1) | (rgb_y == 1) | (rgb_w == 1) | (lab_y == 1)] = 255\n",
    "\n",
    "    return np.dstack(( bin_whiteyellow, bin_whiteyellow, bin_whiteyellow))\n",
    "\n",
    "\n",
    "# Level threshold RHS componenets per tuned threhold values\n",
    "def color_threshold (image):\n",
    "    r_thresh_min = 90\n",
    "    r_thresh_max = 145\n",
    "    h_thresh_min = 20\n",
    "    h_thresh_max = 45\n",
    "    s_thresh_min = 80\n",
    "    s_thresh_max = 255    \n",
    "    r_channel = image[:,:,0]\n",
    "    r_binary = np.zeros_like(r_channel)\n",
    "    r_binary[(r_channel >= r_thresh_min) & (r_channel <= r_thresh_max)] = 1\n",
    "    h_channel = image[:,:,1]\n",
    "    h_binary = np.zeros_like(h_channel)\n",
    "    h_binary[(h_channel >= h_thresh_min) & (h_channel <= h_thresh_max)] = 1\n",
    "    s_channel = image[:,:,2]\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh_min) & (s_channel <= s_thresh_max)] = 1\n",
    " \n",
    "    return (np.dstack(( r_binary, h_binary, s_binary))*255)\n",
    "    \n",
    "# Process RHS component images \n",
    "#  apply Sobel/Laplacian gradient thresholding (absolute, magnitude & angle)\n",
    "def gradient_detect (s_channel, filter_type=\"sobel\", kernel_size=7, abs_thresh=(0, 255), mag_thresh=(0, 255), angle_thresh=(0, np.pi/2)):\n",
    "    \n",
    "    # absolute thresholding\n",
    "    # Apply x or y gradient with the OpenCV Sobel() function\n",
    "    # and take the absolute value\n",
    "    if (filter_type == \"sobel\"):\n",
    "        sobelx = cv2.Sobel(s_channel, cv2.CV_64F, 1, 0, ksize=kernel_size)\n",
    "        sobely = cv2.Sobel(s_channel, cv2.CV_64F, 0, 1, ksize=kernel_size)\n",
    "    else: #\"laplacian\"\n",
    "        sobelx = cv2.Laplacian(s_channel, cv2.CV_64F, ksize=kernel_size)\n",
    "        sobely = cv2.Laplacian(s_channel, cv2.CV_64F, ksize=kernel_size)\n",
    "    # Rescale back to 8 bit integer\n",
    "    scaled_sobelx = np.uint8(255*np.absolute(sobelx)/np.max(np.absolute(sobelx)))\n",
    "    scaled_sobely = np.uint8(255*np.absolute(sobely)/np.max(np.absolute(sobely)))\n",
    "    # Create a copy and apply the threshold\n",
    "    abs_binary_x = np.zeros_like(scaled_sobelx)\n",
    "    abs_binary_y = np.zeros_like(scaled_sobely)\n",
    "    # Here I'm using inclusive (>=, <=) thresholds, but exclusive is ok too\n",
    "    abs_binary_x[(scaled_sobelx >= abs_thresh[0]) & (scaled_sobelx <= abs_thresh[1])] = 1\n",
    "    abs_binary_y[(scaled_sobely >= abs_thresh[0]) & (scaled_sobely <= abs_thresh[1])] = 1\n",
    "\n",
    "    # magnitude thresholding\n",
    "    # Calculate the gradient magnitude\n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # Rescale to 8 bit\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8) \n",
    "    # Create a binary image of ones where threshold is met, zeros otherwise\n",
    "    mag_binary = np.zeros_like(gradmag)\n",
    "    mag_binary[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 1\n",
    "\n",
    "    # angle thresholding\n",
    "    # Take the absolute value of the gradient direction, \n",
    "    # apply a threshold, and create a binary image result\n",
    "    absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    dir_binary =  np.zeros_like(absgraddir)\n",
    "    dir_binary[(absgraddir >= angle_thresh[0]) & (absgraddir <= angle_thresh[1])] = 1\n",
    "\n",
    "    # generate combined thresholded S-channel image\n",
    "    combined = np.zeros_like(dir_binary)\n",
    "    combined[((abs_binary_x == 1) & (abs_binary_y == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 255\n",
    "\n",
    "    return combined.astype(np.uint8)\n",
    "\n",
    "def gradient_threshold (image):\n",
    "    #resultR = gradient_detect(image[:,:,0], filter_type=\"laplacian\", abs_thresh=(20, 160), mag_thresh=(20, 160), angle_thresh=(0.5, np.pi/2))\n",
    "    #resultH = gradient_detect(image[:,:,1], filter_type=\"laplacian\", abs_thresh=(20, 160), mag_thresh=(20, 160), angle_thresh=(0.5, np.pi/2))\n",
    "    resultS = gradient_detect(image[:,:,2], filter_type=\"sobel\", abs_thresh=(30, 255), mag_thresh=(20, 255), angle_thresh=(0.5, np.pi/2))\n",
    "    result = np.zeros_like(resultS)\n",
    "    #result[((resultR == 255) & (resultH == 255)) | (resultS == 255)] = 255\n",
    "    result = resultS\n",
    "    \n",
    "    return np.dstack((result, result, result))\n",
    "    #return result.astype(np.uint8)\n",
    "\n",
    "def warp_image (image):\n",
    "    return cv2.warpPerspective(image, M, (image.shape[1], image.shape[0]))\n",
    "\n",
    "# Lane line detect using sliding-window histogram tracking\n",
    "def find_lane_pixels (binary_warped, prev_left_lane_inds, prev_right_left_lane_inds):\n",
    "    # Take a histogram of the bottom third of the image \n",
    "    #  (guard against curved lanes by looking at immediate road lines next to car front)\n",
    "    histogram = np.sum(binary_warped[int(binary_warped.shape[0]/3):,:], axis=0)\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # HYPERPARAMETERS\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 110\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n",
    "        (win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
    "        (win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        \n",
    "        # Identify the nonzero pixels in x and y within the window #\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        # Re-use lane indicators from last available frame\n",
    "        left_lane_inds = prev_left_lane_inds\n",
    "        right_lane_inds = prev_right_lane_inds\n",
    "        pass\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty, out_img, left_lane_inds, right_lane_inds\n",
    "\n",
    "def fit_polynomial (binary_warped, prev_left_lane_inds, prev_right_left_lane_inds):\n",
    "    # Find our lane pixels first\n",
    "    leftx, lefty, rightx, righty, out_img, prev_left_lane_ids, prev_right_lane_inds = find_lane_pixels(binary_warped, prev_left_lane_inds, prev_right_left_lane_inds)\n",
    "\n",
    "    idx=0\n",
    "    #print(leftx[idx], lefty[idx], rightx[idx], righty[idx])\n",
    "    \n",
    "    # Fit a second order polynomial to each using `np.polyfit`\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    left_fit_m = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_m = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    try:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "        left_fitx_m= left_fit_m[0]*ploty**2 + left_fit_m[1]*ploty + left_fit_m[2]\n",
    "        right_fitx_m = right_fit_m[0]*ploty**2 + right_fit_m[1]*ploty + right_fit_m[2]\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        left_fitx = 1*ploty**2 + 1*ploty\n",
    "        right_fitx = 1*ploty**2 + 1*ploty\n",
    "        left_fitx_m = 1*ploty**2 + 1*ploty\n",
    "        right_fitx_m = 1*ploty**2 + 1*ploty\n",
    "    center_fitx = np.mean([left_fit[0],right_fit[0]])*ploty**2 + np.mean([left_fit[1],right_fit[1]])*ploty + np.mean([left_fit[2],right_fit[2]])\n",
    "\n",
    "    ## Visualization ##\n",
    "    # Colors in the left and right lane regions\n",
    "    out_img[lefty, leftx] = [255, 0, 0] # red for left lane\n",
    "    out_img[righty, rightx] = [0, 0, 255] # blue for right lane\n",
    "    ## draw lanelines & center track\n",
    "    #out_img[ploty.astype(np.int64), left_fitx.astype(np.int64)] = [255, 255, 0] # yellow for left polynomial fit\n",
    "    #out_img[ploty.astype(np.int64), right_fitx.astype(np.int64)] = [255, 255, 0] # yellow for right polynomial fit\n",
    "    #out_img[ploty.astype(np.int64), center_fitx.astype(np.int64)] = [255, 255, 255] # yellow for road center \n",
    "\n",
    "    return out_img, ploty, left_fitx, right_fitx, center_fitx, left_fit_m, right_fit_m\n",
    "\n",
    "def measure_curvature_real(ploty, left_fit_cr, right_fit_cr):\n",
    "    '''\n",
    "    Calculates the curvature of polynomial functions in kilometers.\n",
    "    '''\n",
    "    # Define y-value where we want radius of curvature\n",
    "    # We'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = np.max(ploty)\n",
    "    \n",
    "    # Calculation of R_curve (radius of curvature)\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "\n",
    "    return left_curverad/1000., right_curverad/1000.\n",
    "\n",
    "def draw_lane_lines (img, left_fitx, right_fitx):\n",
    "    yMax = img.shape[0]\n",
    "    ploty = np.linspace(0, yMax - 1, yMax)\n",
    "    color_warp = np.zeros_like(img).astype(np.uint8)\n",
    "    \n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    \n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    \n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (img.shape[1], img.shape[0])) \n",
    "    return cv2.addWeighted(img, 1, newwarp, 0.3, 0)\n",
    "\n",
    "def annotate_lanes (img, left_fit_m, right_fit_m, leftCurvature, rightCurvature, fontScale=.75):\n",
    "    # Calculate vehicle center\n",
    "    xMax = img.shape[1]*xm_per_pix\n",
    "    yMax = img.shape[0]*ym_per_pix\n",
    "    vehicleCenter = xMax / 2\n",
    "    \n",
    "    lineLeft = left_fit_m[0]*yMax**2 + left_fit_m[1]*yMax + left_fit_m[2]\n",
    "    lineRight = right_fit_m[0]*yMax**2 + right_fit_m[1]*yMax + right_fit_m[2]\n",
    "    lineMiddle = lineLeft + (lineRight - lineLeft)/2\n",
    "    diffFromVehicle = lineMiddle - vehicleCenter\n",
    "    if diffFromVehicle > 0:\n",
    "        message = '{:.2f} m right'.format(diffFromVehicle)\n",
    "    else:\n",
    "        message = '{:.2f} m left'.format(-diffFromVehicle)\n",
    "    \n",
    "    # Draw info\n",
    "    font = cv2.FONT_HERSHEY_COMPLEX\n",
    "    fontColor = (124, 252, 0) #(255, 255, 255)\n",
    "    cv2.putText(img, 'Left curvature: {:.0f} m'.format(leftCurvature), (50, 50), font, fontScale, fontColor, 2)\n",
    "    cv2.putText(img, 'Right curvature: {:.0f} m'.format(rightCurvature), (50, 75), font, fontScale, fontColor, 2)\n",
    "    cv2.putText(img, 'Vehicle is {} of center'.format(message), (50, 100), font, fontScale, fontColor, 2)\n",
    "     \n",
    "    return img    \n",
    "    \n",
    "def draw_lanes_on_image (img, left_fitx, right_fitx, left_fit_m, right_fit_m, leftCurvature, rightCurvature):\n",
    "    \n",
    "    yMax = img.shape[0]\n",
    "    ploty = np.linspace(0, yMax - 1, yMax)\n",
    "    color_warp = np.zeros_like(img).astype(np.uint8)\n",
    "    \n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    \n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    \n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (img.shape[1], img.shape[0])) \n",
    "\n",
    "    return cv2.addWeighted(img, 1, newwarp, 0.3, 0)\n",
    "\n",
    "\n",
    "def window_mask(width, height, img_ref, center,level):\n",
    "    output = np.zeros_like(img_ref)\n",
    "    output[int(img_ref.shape[0]-(level+1)*height):int(img_ref.shape[0]-level*height),max(0,int(center-width/2)):min(int(center+width/2),img_ref.shape[1])] = 1\n",
    "    return output\n",
    "\n",
    "def find_window_centroids(image, window_width=50, window_height=50, margin=100):\n",
    "    \n",
    "    window_centroids = [] # Store the (left,right) window centroid positions per level\n",
    "    window = np.ones(window_width) # Create our window template that we will use for convolutions\n",
    "    \n",
    "    # First find the two starting positions for the left and right lane by using np.sum to get the vertical image slice\n",
    "    # and then np.convolve the vertical image slice with the window template \n",
    "    \n",
    "    # Sum quarter bottom of image to get slice, could use a different ratio\n",
    "    l_sum = np.sum(image[int(3*image.shape[0]/4):,:int(image.shape[1]/2)], axis=0)\n",
    "    l_center = np.argmax(np.convolve(window,l_sum))-window_width/2\n",
    "    r_sum = np.sum(image[int(3*image.shape[0]/4):,int(image.shape[1]/2):], axis=0)\n",
    "    r_center = np.argmax(np.convolve(window,r_sum))-window_width/2+int(image.shape[1]/2)\n",
    "    \n",
    "    # Add what we found for the first layer\n",
    "    window_centroids.append((l_center,r_center))\n",
    "    \n",
    "    # Go through each layer looking for max pixel locations\n",
    "    for level in range(1,(int)(image.shape[0]/window_height)):\n",
    "\t    # convolve the window into the vertical slice of the image\n",
    "\t    image_layer = np.sum(image[int(image.shape[0]-(level+1)*window_height):int(image.shape[0]-level*window_height),:], axis=0)\n",
    "\t    conv_signal = np.convolve(window, image_layer)\n",
    "\t    # Find the best left centroid by using past left center as a reference\n",
    "\t    # Use window_width/2 as offset because convolution signal reference is at right side of window, not center of window\n",
    "\t    offset = window_width/2\n",
    "\t    l_min_index = int(max(l_center+offset-margin,0))\n",
    "\t    l_max_index = int(min(l_center+offset+margin,image.shape[1]))\n",
    "\t    l_center = np.argmax(conv_signal[l_min_index:l_max_index])+l_min_index-offset\n",
    "\t    # Find the best right centroid by using past right center as a reference\n",
    "\t    r_min_index = int(max(r_center+offset-margin,0))\n",
    "\t    r_max_index = int(min(r_center+offset+margin,image.shape[1]))\n",
    "\t    r_center = np.argmax(conv_signal[r_min_index:r_max_index])+r_min_index-offset\n",
    "\t    # Add what we found for that layer\n",
    "\t    window_centroids.append((l_center,r_center))\n",
    "\n",
    "    return window_centroids\n",
    "\n",
    "def roi_mask (img, maskfit_factor_horiz=3.1, maskfit_factor_vert=1.8):\n",
    "    # define region of interest, 4-sided polygon\n",
    "    ysize = img.shape[0]\n",
    "    xsize = img.shape[1]\n",
    "    offset_height = ysize/4 # 1/4th bottom is always kept unmasked\n",
    "    left_end = np.array([0, ysize])\n",
    "    right_end = np.array([xsize, ysize])\n",
    "    left_bottom = np.array([0, ysize-offset_height])\n",
    "    right_bottom = np.array([xsize, ysize-offset_height])\n",
    "    # check ROI top vertices don't cross\n",
    "    if (xsize/maskfit_factor_horiz < xsize/2):\n",
    "        left_top = np.array([xsize/maskfit_factor_horiz, ysize/maskfit_factor_vert])\n",
    "        right_top = np.array([xsize-xsize/maskfit_factor_horiz, ysize/maskfit_factor_vert])\n",
    "    else:\n",
    "        left_top = np.array([xsize/2, ysize/maskfit_factor_vert])\n",
    "        right_top = np.array([xsize/2, ysize/maskfit_factor_vert])\n",
    "    roi_vertices = np.array([[left_end,left_bottom,left_top,right_top,right_bottom,right_end]], dtype=np.int32)\n",
    "    \n",
    "    # apply mask\n",
    "    mask = np.zeros_like(img)   \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, roi_vertices, ignore_mask_color)\n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    img = cv2.bitwise_and(img, mask)\n",
    "\n",
    "    return img\n",
    "\n",
    "def VideoLaneTrackingPipeline(image):\n",
    "    #\n",
    "    # Camera distortion model processing\n",
    "    #\n",
    "    img = image_undistort(image)\n",
    "    \n",
    "    #\n",
    "    # Color processing\n",
    "    #\n",
    "    if (0):\n",
    "        img = color_transform(img)\n",
    "        img = color_threshold(img)     \n",
    "    else:\n",
    "        img = color_select (img)\n",
    "\n",
    "    #\n",
    "    # RoI Masking & Gradient processing\n",
    "    #\n",
    "    img = roi_mask(img)\n",
    "    img = gradient_threshold(img)\n",
    "    \n",
    "    #\n",
    "    # Lane marker detection & tracking    \n",
    "    #\n",
    "    img = warp_image(img)\n",
    "    img, ploty, l_fitx, r_fitx, lr_fitx, l_fit_m, r_fit_m = fit_polynomial(img[:,:,2], prev_left_lane_inds, prev_left_lane_inds)\n",
    "    left_curverad, right_curverad = measure_curvature_real(ploty, l_fit_m, r_fit_m)\n",
    "    #print('Left : {:.2f} km, Right : {:.2f} km'.format(left_curverad, right_curverad))\n",
    "    \n",
    "    #\n",
    "    # Video frame annotation\n",
    "    #\n",
    "    img = draw_lane_lines(image, l_fitx, r_fitx)\n",
    "    ##img = draw_lanes_on_image (image, l_fitx, r_fitx, l_fit_m, r_fit_m, left_curverad, right_curverad)\n",
    "    img = annotate_lanes(img, l_fit_m, r_fit_m, left_curverad, right_curverad)\n",
    "\n",
    "    return img\n",
    "\n",
    "\"\"\"\n",
    "#\n",
    "# Process images in test directory\n",
    "#\n",
    "out_images = []\n",
    "files = os.listdir(\"./test_images/\")\n",
    "for file in files:\n",
    "    iimg = cv2.imread(\"./test_images/\"+file)\n",
    "    oimg = VideoLaneTrackingPipeline(iimg)\n",
    "    out_images.append(oimg)\n",
    "    cv2.imwrite('./output_images/'+file, oimg) \n",
    "\n",
    "imgLength = len(out_images)\n",
    "rows = 2\n",
    "cols = int(len(out_images)/rows)\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(15,4))\n",
    "plt.suptitle('Test Images With Lane Markers')\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "#plt.tight_layout()\n",
    "indexes = range(cols * rows)\n",
    "for ax, index in zip(axes.flat, indexes):    \n",
    "    ax.imshow(cv2.cvtColor(out_images[index], cv2.COLOR_BGR2RGB))\n",
    "    #ax.imshow(out_images[index], cmap='gray')\n",
    "    ax.axis('off')\n",
    "\"\"\"\n",
    "    \n",
    "\n",
    "#\n",
    "# Process videos in test directory\n",
    "#\n",
    "files = os.listdir(\"./Resources/test_videos/\")\n",
    "for file in files:\n",
    "    video_output = \"./Resources/test_videos_output/\"+file    \n",
    "    ## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "    ## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "    ## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "    clip1 = VideoFileClip(\"./Resources/test_videos/\"+file).subclip(5,10)\n",
    "    #clip1.reader.close()\n",
    "    #clip1.audio.reader.close_proc()\n",
    "    #clip1.close()\n",
    "    video_clip = clip1.fl_image(VideoLaneTrackingPipeline) #NOTE: this function expects color images!!\n",
    "    #video_clip = clip1\n",
    "    %time video_clip.write_videofile(video_output, audio=False)\n",
    "    del clip1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
